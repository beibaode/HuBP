{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4fd7a53",
   "metadata": {},
   "source": [
    "# Hu+BP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219d7738",
   "metadata": {},
   "source": [
    "## 0.生成Hu值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bb1e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hu不变矩代码 python+opencv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "path='./data/Hu_data/'\n",
    "\n",
    "lbe = LabelEncoder()\n",
    "mms = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "def Hu_moments(img):\n",
    "    '''\n",
    "    opencv_python自带求矩以及不变矩的函数\n",
    "    :param img: 灰度图像，对于二值图像来说就只有两个灰度0和255\n",
    "    :return: 返回以10为底对数化后的hu不变矩\n",
    "    '''\n",
    "    moments = cv2.moments(img)  # 返回的是一个字典，三阶及以下的几何矩（mpq）、中心矩(mupq)和归一化的矩(nupq)\n",
    "    humoments = cv2.HuMoments(moments)  # 根据几何矩（mpq）、中心矩(mupq)和归一化的矩(nupq)计算出hu不变矩\n",
    "    # 因为直接计算出来的矩可能很小或者很大，因此取对数好比较,这里的对数底数为e,通过对数除法的性质将其转换为以10为底的对数\n",
    "    humoment = (np.log(np.abs(humoments))) / np.log(10)\n",
    "    humoment = np.reshape(humoment,(1,7))[0]\n",
    "    return humoment\n",
    "if __name__ == '__main__':\n",
    "    hu=[]\n",
    "    img_col=[]\n",
    "    file_list = os.listdir(path)\n",
    "    for img_name in file_list:\n",
    "        img = cv2.imread(path+img_name, 0) #读入图片\n",
    "        humoments = Hu_moments(img)\n",
    "        img_col.append(img_name.split('_')[0])\n",
    "        hu.append(humoments)\n",
    "    hu=pd.DataFrame(hu)\n",
    "    hu[7]=img_col\n",
    "    \n",
    "    \n",
    "    hu[7] = lbe.fit_transform(hu[7])\n",
    "    hu.sort_values(by=[7],inplace=True)\n",
    "    hu.to_csv('./data/hu.csv',index=False,header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef0e8f5",
   "metadata": {},
   "source": [
    "## 1.BP神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2156fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import torch.nn.functional as F\n",
    "\n",
    "path='./data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d13ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Z_ScoreNormalization(x):            #归一化\n",
    "    mu=np.average(x)\n",
    "    sigma=np.std(x)\n",
    "    x = (x - mu) / sigma\n",
    "    return x\n",
    "\n",
    "def norm_all(x):            #实现了每列归一化\n",
    "    x=np.array(x)[:,:-1]\n",
    "    h,w=x.shape\n",
    "    # print(h,w)\n",
    "    x=x.T\n",
    "    rlt=[]\n",
    "    for i in range(w):\n",
    "        # print('guagua',x[i])\n",
    "        tmp=Z_ScoreNormalization(x[i])\n",
    "        rlt.append(tmp)\n",
    "    rlt=np.array(rlt).T\n",
    "    return rlt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e4e659",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DealDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        xy = np.loadtxt(path+'./hu.csv', delimiter=',', dtype=np.float32)  # 使用numpy读取数据\n",
    "        lab=xy[:,-1].reshape(-1,1)\n",
    "        xy=norm_all(xy)\n",
    "        xy=np.concatenate((xy,lab),1)\n",
    "        self.x_data = torch.from_numpy(xy[:, 0:-1])\n",
    "        self.y_data = torch.from_numpy(xy[:, -1]).long()\n",
    "        self.len = xy.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16075ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hu数据加载、划分数据集\n",
    "data = DealDataset()\n",
    "train_set, test_set = random_split(data,lengths=[720, 180])  #300个样本，按8:2划分训练集和验证集\n",
    "\n",
    "train_data = DataLoader(train_set, batch_size=4, shuffle=False)  # 训练数据\n",
    "test_data = DataLoader(test_set, batch_size=4, shuffle=False)  # 测试数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961bd33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型定义\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(7,5)\n",
    "        self.linear2 = torch.nn.Linear(5,3)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = x.view(-1,7) # 改变张量形状。把输入展开成若干行，7列\n",
    "        x = F.leaky_relu(self.linear1(x))\n",
    "        return self.linear2(x) #最后一层不做激活，因为下一步输入到交叉损失函数中，交叉熵包含了激活层\n",
    "    \n",
    "model = Net()\n",
    "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f1ba21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 损失函数和优化器\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01) #, momentum= 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0622bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    running_loss=0.0\n",
    "    for batch_idx,data in enumerate(train_data,0):\n",
    "        inputs,labels=data\n",
    "        inputs,labels=inputs.to(device),labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs=model(inputs)\n",
    "        loss=criterion(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss+=loss.item()\n",
    "        if batch_idx%100==99:\n",
    "            print('[%d,%5d] loss:%.3f'%(epoch+1,batch_idx+1,running_loss/100))\n",
    "            running_loss=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b2584e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    correct=0\n",
    "    total=0\n",
    "    with torch.no_grad():\n",
    "        for data in test_data:\n",
    "            images,labels=data\n",
    "            images,labels=images.to(device),labels.to(device)\n",
    "            outputs=model(images)\n",
    "            _,predicted=torch.max(outputs.data,dim=1)\n",
    "            total+=labels.size(0)\n",
    "            correct+=(predicted==labels).sum().item()\n",
    "    print('Accuracy on test set:%d %%'%(100*correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a05bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "    for epoch in range(100):\n",
    "        train(epoch)\n",
    "        test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97e4160",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
